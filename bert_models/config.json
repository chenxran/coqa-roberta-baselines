{
    "trainset": "data/coqa-bert-train.json",
    "devset": "data/coqa-bert-dev.json",
    "testset": null,
    "dir": "bert_models",
    "pretrained": null,
    "random_seed": 123,
    "cuda": true,
    "cuda_id": 0,
    "debug": false,
    "n_history": 2,
    "cased": true,
    "min_freq": 20,
    "top_vocab": 100000,
    "rnn_padding": false,
    "embed_file": null,
    "embed_size": null,
    "embed_type": "glove",
    "hidden_size": 300,
    "num_layers": 3,
    "rnn_type": "lstm",
    "concat_rnn_layers": true,
    "question_merge": "self_attn",
    "use_qemb": true,
    "f_qem": true,
    "f_pos": false,
    "f_ner": false,
    "sum_loss": false,
    "doc_self_attn": false,
    "resize_rnn_input": false,
    "span_dependency": true,
    "fix_embeddings": false,
    "dropout_rnn": 0.3,
    "dropout_emb": 0.5,
    "dropout_ff": 0.5,
    "dropout_rnn_output": true,
    "variational_dropout": true,
    "word_dropout": false,
    "max_length": 512,
    "gradient_accumulation_steps": 6,
    "optimizer": "adamw",
    "learning_rate": 5e-05,
    "grad_clipping": 1.0,
    "weight_decay": 0.0,
    "momentum": 0.0,
    "batch_size": 8,
    "max_epochs": 4,
    "verbose": 1,
    "shuffle": false,
    "max_answer_len": 15,
    "predict_train": true,
    "out_predictions": true,
    "predict_raw_text": true,
    "save_params": true
}